args_map:
  log_dir: train.log_dir
  seed: train.seed
  use_train_subset: data.use_train_subset
  use_train_repeat: data.use_train_repeat
  use_val_subset: data.use_val_subset
  use_initiate: train.use_initiate
  batch_size: data.batch_size
  gradient_accumulate: data.gradient_accumulate
  epochs: train.epochs
  lr: train.learning_rate
  mul_lr: train.mul_learning_rate
  num_codes: model.autoencoder.params.quantize.params.n_e
  enterpoint: train.enterpoint
  code_path: train.code_path
  embed_path: train.embed_path
  mode: mode
mode: train
use_amp: false
train:
  epochs: 50
  seed: 42
  learning_rate: 4.5e-6
  mul_learning_rate: 1.0
  weight_decay: 0.05
  visualize_interval: 50
  pipeline: ae_disc # ae / ae_disc
  use_initiate: kmeans
  enterpoint: null
  nnodes: 1
  dist_url: tcp://localhost:10001
  code_path: null
  embed_path: null
data:
  preprocess: plain
  batch_size: 8
  test_batch_size: 8
  gen_embed_batch_size: 8
  gradient_accumulate: 1
  use_train_subset: null
  use_train_repeat: null
  use_val_subset: null
  train:
    target: optvq.data.dataset.ImageNetDataset
    params:
      root: /data1/data/imagenet/train
      convert_to_numpy: true
      post_normalize: plain
      transform: 
        target: optvq.data.preprocessor.imagenet_preprocessor
        params:
          resize: 256
          is_train: true
  val:
    target: optvq.data.dataset.ImageNetDataset
    params:
      root: /data1/data/imagenet/val
      convert_to_numpy: true
      post_normalize: plain
      transform: 
        target: optvq.data.preprocessor.imagenet_preprocessor
        params:
          resize: 256
          is_train: false
model:
  autoencoder:
    target: optvq.models.vqgan.VQModel
    params:
      use_connector: true
      encoder:
        target: optvq.models.backbone.diffusion.Encoder
        params:
          double_z: false
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 1, 2, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: [8]
          dropout: 0.0
      decoder:
        target: optvq.models.backbone.diffusion.Decoder
        params:
          double_z: false
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 1, 2, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: [8]
          dropout: 0.0
      quantize:
        target: optvq.models.quantizer.VectorQuantizerSinkhorn
        params:
          n_e: 16384
          e_dim: 256
          beta: 0.25
          use_proj: true
          fix_codes: false
          epsilon: 10
          n_iters: 5
          normalize_mode: all
          use_prob: false
          start_quantize_steps: null
          num_head: 8
          loss_q_type: l2
      loss:
        target: optvq.losses.aeloss_disc.AELossWithDisc
        params:
          loss_l1_weight: 1.0
          loss_l2_weight: 1.0
          loss_p_weight: 3.0
          loss_q_weight: 1.0
          loss_g_weight: 1.0
          loss_d_weight: 1.0
          disc_in_channels: 3
          disc_num_layers: 3
          disc_start: 150000
